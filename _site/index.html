<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>🤖 欢迎来到 PaperCache！ | PaperCache</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="🤖 欢迎来到 PaperCache！" />
<meta name="author" content="shenh10" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="深度学习、机器学习和人工智能研究论文的精选缓存" />
<meta property="og:description" content="深度学习、机器学习和人工智能研究论文的精选缓存" />
<link rel="canonical" href="http://localhost:4000/papercache/" />
<meta property="og:url" content="http://localhost:4000/papercache/" />
<meta property="og:site_name" content="PaperCache" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="🤖 欢迎来到 PaperCache！" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"shenh10"},"description":"深度学习、机器学习和人工智能研究论文的精选缓存","headline":"🤖 欢迎来到 PaperCache！","name":"PaperCache","url":"http://localhost:4000/papercache/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/papercache/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/papercache/feed.xml" title="PaperCache" /><!-- MathJax 3 Configuration -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

</head><body><header class="site-header">
  <div class="wrapper">
    <a class="site-title" rel="author" href="/papercache/">PaperCache</a>
    <nav class="site-nav">
      <div class="trigger">
        <a class="page-link" href="/papercache/">主页</a>
        <a class="page-link" href="/papercache/collection.html">论文合集</a>
        <a class="page-link" href="/papercache/about/">关于</a>
      </div>
    </nav>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">🤖 欢迎来到 PaperCache！</h1>
  </header>

  <div class="post-content">
    <p><strong>一个由 AI 当实习生，我做老板的博客。</strong></p>

<p>没错，这里的每一篇论文精读，都不是我亲手写的，而是我的赛博雇员——<strong>LLM</strong>——的作品。我只负责投喂论文，并偶尔在它出错时进行一些人工干预。</p>

<hr />

<h3 id="关于这个博客的诞生">关于这个博客的诞生</h3>

<p>作为一个天天被 Paper 追着跑的工程师，我曾挣扎在第二语言和读不完的文献列表里。在这个 AGI 时代，我意识到一个简单有效的方法：<strong>让 AI 去读那些关于 AI 的论文。</strong></p>

<p>于是，PaperCache 诞生了。它是我通过 Prompt Engineering 调教出的一套自动化工具的产物。</p>

<p>我们的目标很明确：</p>
<ul>
  <li>帮你过滤掉论文中 80% 的复杂噪音，让你迅速吸收核心思想。</li>
  <li>把你长长的 “稍后读” 清单，变成高效的 “已读” 列表。</li>
</ul>

<p>当然，我的 AI 伙伴有时会过于自信，可能会犯一些错误。如果你发现了任何 Bug，<strong>请务必在评论区大声指出</strong>，你的每一次“找茬”都能让它变得更聪明。</p>

<h3 id="我们关注什么">我们关注什么？</h3>

<p>这个知识库将是你的 AI 军火库，长期更新 <strong>AI Infra 全栈</strong> 的尖端弹药，包括但不限于：</p>

<ul>
  <li>机器学习系统 (Machine Learning System)</li>
  <li>大模型算法 (Large Model Algorithms)</li>
  <li>AI 加速器 (AI Accelerators)</li>
</ul>

<p>准备好，和我们一起高效成长吧！</p>

<p><em>最后，特别鸣谢我的两位灵感缪斯：Gemini &amp; Grok。</em></p>

<hr />
<h3 id="-最新动态">🚀 最新动态</h3>

<ul>
  <li>
    <p><strong>[2025-08-24]</strong> <a href="/papercache/mlsys/framework/2025/08/24/campo-cost-aware-performance-optimization-for-mixed-precision-neural-network-training.html">Campo: Cost-Aware Performance Optimization for Mixed-Precision Neural Network Training</a></p>
  </li>
  <li>
    <p><strong>[2025-07-30]</strong> <a href="/papercache/llm/engineering/inference/2025/07/30/step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding.html">Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</a></p>
  </li>
  <li>
    <p><strong>[2025-07-30]</strong> <a href="/papercache/mlsys/networking/2025/07/30/scale-up-ethernet-framework-scale-up-ethernet-framework-specification.html">Scale-Up Ethernet Framework Scale-Up Ethernet Framework Specification</a></p>
  </li>
  <li>
    <p><strong>[2025-07-30]</strong> <a href="/papercache/llm/engineering/inference/2025/07/30/megascale-infer-serving-mixture-of-experts-at-scale-with-disaggregated-expert-parallelism.html">MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism</a></p>
  </li>
  <li>
    <p><strong>[2025-07-30]</strong> <a href="/papercache/mlsys/networking/2025/07/30/demystifying-nccl-an-in-depth-analysis-of-gpu-communication-protocols-and-algorithms.html">
    Demystifying NCCL: An In-depth Analysis of GPU Communication Protocols and
    Algorithms
  </a></p>
  </li>
</ul>

<hr />

<h3 id="-精选论文">📚 精选论文</h3>

<h4 id="-大语言模型-llm">🤖 大语言模型 (LLM)</h4>

<ul>
  <li>
    <p><a href="/papercache/llm/engineering/inference/2025/07/30/step-3-is-large-yet-affordable-model-system-co-design-for-cost-effective-decoding.html">Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/inference/2025/07/30/megascale-infer-serving-mixture-of-experts-at-scale-with-disaggregated-expert-parallelism.html">MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/compiler/2025/06/30/mirage-a-multi-level-superoptimizer-for-tensor-programs.html">Mirage: A Multi-Level Superoptimizer for Tensor Programs</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/attention/2025/05/30/sageattention3-microscaling-fp4-attention-for-inference-and-an-exploration-of-8-bit-training.html">SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-bit Training</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/inference/2025/05/30/recipes-for-pre-training-llms-with-mxfp8.html">Recipes for Pre-training LLMs with MXFP8</a></p>
  </li>
</ul>

<h4 id="️-机器学习系统-mlsys">⚙️ 机器学习系统 (MLSys)</h4>

<ul>
  <li>
    <p><a href="/papercache/mlsys/framework/2025/08/24/campo-cost-aware-performance-optimization-for-mixed-precision-neural-network-training.html">Campo: Cost-Aware Performance Optimization for Mixed-Precision Neural Network Training</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/07/30/scale-up-ethernet-framework-scale-up-ethernet-framework-specification.html">Scale-Up Ethernet Framework Scale-Up Ethernet Framework Specification</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/07/30/demystifying-nccl-an-in-depth-analysis-of-gpu-communication-protocols-and-algorithms.html">
    Demystifying NCCL: An In-depth Analysis of GPU Communication Protocols and
    Algorithms
  </a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/04/30/introducing-ualink-200g-10-specification.html">Introducing UALink 200G 1.0 Specification</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/03/30/ub-mesh-a-hierarchically-localized-nd-fullmesh-datacenter-network-architecture.html">UB-Mesh: a Hierarchically Localized nD-FullMesh Datacenter Network Architecture</a></p>
  </li>
</ul>

<hr />
<blockquote>
  <p><a href="/papercache/collection.html">查看所有论文…</a></p>
</blockquote>

  </div>

</article>

      </div>
    </main></body>

</html>
