<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ğŸ¤– æ¬¢è¿æ¥åˆ° PaperCacheï¼ | PaperCache</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="ğŸ¤– æ¬¢è¿æ¥åˆ° PaperCacheï¼" />
<meta name="author" content="shenh10" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="æ·±åº¦å­¦ä¹ ã€æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½ç ”ç©¶è®ºæ–‡çš„ç²¾é€‰ç¼“å­˜" />
<meta property="og:description" content="æ·±åº¦å­¦ä¹ ã€æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½ç ”ç©¶è®ºæ–‡çš„ç²¾é€‰ç¼“å­˜" />
<link rel="canonical" href="http://localhost:4000/papercache/" />
<meta property="og:url" content="http://localhost:4000/papercache/" />
<meta property="og:site_name" content="PaperCache" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ğŸ¤– æ¬¢è¿æ¥åˆ° PaperCacheï¼" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"shenh10"},"description":"æ·±åº¦å­¦ä¹ ã€æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½ç ”ç©¶è®ºæ–‡çš„ç²¾é€‰ç¼“å­˜","headline":"ğŸ¤– æ¬¢è¿æ¥åˆ° PaperCacheï¼","name":"PaperCache","url":"http://localhost:4000/papercache/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/papercache/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/papercache/feed.xml" title="PaperCache" /><!-- MathJax 3 Configuration -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\(', '\)']],
        displayMath: [['$$', '$$'], ['\[', '\]']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>

  <!-- Busuanzi Analytics -->
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</head><body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/papercache/">PaperCache</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/papercache/about/">å…³äº</a><a class="page-link" href="/papercache/collection.html">è®ºæ–‡åˆé›†</a><a class="page-link" href="/papercache/">ğŸ¤– æ¬¢è¿æ¥åˆ° PaperCacheï¼</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">ğŸ¤– æ¬¢è¿æ¥åˆ° PaperCacheï¼</h1>
  </header>

  <div class="post-content">
    <p><strong>ä¸€ä¸ªç”± AI å½“å®ä¹ ç”Ÿï¼Œæˆ‘åšè€æ¿çš„åšå®¢ã€‚</strong></p>

<p>æ²¡é”™ï¼Œè¿™é‡Œçš„æ¯ä¸€ç¯‡è®ºæ–‡ç²¾è¯»ï¼Œéƒ½ä¸æ˜¯æˆ‘äº²æ‰‹å†™çš„ï¼Œè€Œæ˜¯æˆ‘çš„èµ›åšé›‡å‘˜â€”â€”<strong>LLM</strong>â€”â€”çš„ä½œå“ã€‚æˆ‘åªè´Ÿè´£æŠ•å–‚è®ºæ–‡ï¼Œå¹¶å¶å°”åœ¨å®ƒå‡ºé”™æ—¶è¿›è¡Œä¸€äº›äººå·¥å¹²é¢„ã€‚</p>

<hr />

<h3 id="å…³äºè¿™ä¸ªåšå®¢çš„è¯ç”Ÿ">å…³äºè¿™ä¸ªåšå®¢çš„è¯ç”Ÿ</h3>

<p>ä½œä¸ºä¸€ä¸ªå¤©å¤©è¢« Paper è¿½ç€è·‘çš„å·¥ç¨‹å¸ˆï¼Œæˆ‘æ›¾æŒ£æ‰åœ¨ç¬¬äºŒè¯­è¨€å’Œè¯»ä¸å®Œçš„æ–‡çŒ®åˆ—è¡¨é‡Œã€‚åœ¨è¿™ä¸ª AGI æ—¶ä»£ï¼Œæˆ‘æ„è¯†åˆ°ä¸€ä¸ªç®€å•æœ‰æ•ˆçš„æ–¹æ³•ï¼š<strong>è®© AI å»è¯»é‚£äº›å…³äº AI çš„è®ºæ–‡ã€‚</strong></p>

<p>äºæ˜¯ï¼ŒPaperCache è¯ç”Ÿäº†ã€‚å®ƒæ˜¯æˆ‘é€šè¿‡ Prompt Engineering è°ƒæ•™å‡ºçš„ä¸€å¥—è‡ªåŠ¨åŒ–å·¥å…·çš„äº§ç‰©ã€‚</p>

<p>æˆ‘ä»¬çš„ç›®æ ‡å¾ˆæ˜ç¡®ï¼š</p>
<ul>
  <li>å¸®ä½ è¿‡æ»¤æ‰è®ºæ–‡ä¸­ 80% çš„å¤æ‚å™ªéŸ³ï¼Œè®©ä½ è¿…é€Ÿå¸æ”¶æ ¸å¿ƒæ€æƒ³ã€‚</li>
  <li>æŠŠä½ é•¿é•¿çš„ â€œç¨åè¯»â€ æ¸…å•ï¼Œå˜æˆé«˜æ•ˆçš„ â€œå·²è¯»â€ åˆ—è¡¨ã€‚</li>
</ul>

<p>å½“ç„¶ï¼Œæˆ‘çš„ AI ä¼™ä¼´æœ‰æ—¶ä¼šè¿‡äºè‡ªä¿¡ï¼Œå¯èƒ½ä¼šçŠ¯ä¸€äº›é”™è¯¯ã€‚å¦‚æœä½ å‘ç°äº†ä»»ä½• Bugï¼Œ<strong>è¯·åŠ¡å¿…åœ¨è¯„è®ºåŒºå¤§å£°æŒ‡å‡º</strong>ï¼Œä½ çš„æ¯ä¸€æ¬¡â€œæ‰¾èŒ¬â€éƒ½èƒ½è®©å®ƒå˜å¾—æ›´èªæ˜ã€‚</p>

<h3 id="æˆ‘ä»¬å…³æ³¨ä»€ä¹ˆ">æˆ‘ä»¬å…³æ³¨ä»€ä¹ˆï¼Ÿ</h3>

<p>è¿™ä¸ªçŸ¥è¯†åº“å°†æ˜¯ä½ çš„ AI å†›ç«åº“ï¼Œé•¿æœŸæ›´æ–° <strong>AI Infra å…¨æ ˆ</strong> çš„å°–ç«¯å¼¹è¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š</p>

<ul>
  <li>æœºå™¨å­¦ä¹ ç³»ç»Ÿ (Machine Learning System)</li>
  <li>å¤§æ¨¡å‹ç®—æ³• (Large Model Algorithms)</li>
  <li>AI åŠ é€Ÿå™¨ (AI Accelerators)</li>
</ul>

<p>å‡†å¤‡å¥½ï¼Œå’Œæˆ‘ä»¬ä¸€èµ·é«˜æ•ˆæˆé•¿å§ï¼</p>

<p><em>æœ€åï¼Œç‰¹åˆ«é¸£è°¢æˆ‘çš„ä¸¤ä½çµæ„Ÿç¼ªæ–¯ï¼šGemini &amp; Grokã€‚</em></p>

<hr />
<h3 id="-æœ€æ–°åŠ¨æ€">ğŸš€ æœ€æ–°åŠ¨æ€</h3>

<ul>
  <li>
    <p><strong>[2025-08-25]</strong> <a href="/papercache/llm/engineering/train/2025/08/25/zero-offload-democratizing-billion-scale-model-training.html">ZeRO-Offload: Democratizing Billion-Scale Model Training</a></p>
  </li>
  <li>
    <p><strong>[2025-08-25]</strong> <a href="/papercache/llm/engineering/train/2025/08/25/zero-memory-optimizations-toward-training-trillion-parameter-models.html">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></p>
  </li>
  <li>
    <p><strong>[2025-08-25]</strong> <a href="/papercache/llm/engineering/train/2025/08/25/zero-infinity-breaking-the-gpu-memory-wall-for-extreme-scale-deep-learning.html">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></p>
  </li>
  <li>
    <p><strong>[2025-08-25]</strong> <a href="/papercache/llm/engineering/train/2025/08/25/zero-bubble-pipeline-parallelism.html">ZERO BUBBLE PIPELINE PARALLELISM</a></p>
  </li>
  <li>
    <p><strong>[2025-08-25]</strong> <a href="/papercache/llm/engineering/inference/2025/08/25/with-shared-microexponents-a-little-shifting-goes-a-long-way.html">With Shared Microexponents, A Little Shifting Goes a Long Way</a></p>
  </li>
</ul>

<hr />

<h3 id="-ç²¾é€‰è®ºæ–‡">ğŸ“š ç²¾é€‰è®ºæ–‡</h3>

<h4 id="-å¤§è¯­è¨€æ¨¡å‹-llm">ğŸ¤– å¤§è¯­è¨€æ¨¡å‹ (LLM)</h4>

<ul>
  <li>
    <p><a href="/papercache/llm/engineering/train/2025/08/25/zero-offload-democratizing-billion-scale-model-training.html">ZeRO-Offload: Democratizing Billion-Scale Model Training</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/train/2025/08/25/zero-memory-optimizations-toward-training-trillion-parameter-models.html">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/train/2025/08/25/zero-infinity-breaking-the-gpu-memory-wall-for-extreme-scale-deep-learning.html">ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/train/2025/08/25/zero-bubble-pipeline-parallelism.html">ZERO BUBBLE PIPELINE PARALLELISM</a></p>
  </li>
  <li>
    <p><a href="/papercache/llm/engineering/inference/2025/08/25/with-shared-microexponents-a-little-shifting-goes-a-long-way.html">With Shared Microexponents, A Little Shifting Goes a Long Way</a></p>
  </li>
</ul>

<h4 id="ï¸-æœºå™¨å­¦ä¹ ç³»ç»Ÿ-mlsys">âš™ï¸ æœºå™¨å­¦ä¹ ç³»ç»Ÿ (MLSys)</h4>

<ul>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/08/25/ucx-an-open-source-framework-for-hpc-network-apis-and-beyond.html">UCX: An Open Source Framework for HPC Network APIs and Beyond</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/08/25/ub-mesh-a-hierarchically-localized-nd-fullmesh-datacenter-network-architecture.html">UB-Mesh: a Hierarchically Localized nD-FullMesh Datacenter Network Architecture</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/gpu/2025/08/25/stream-k-work-centric-parallel-decomposition-for-dense-matrix-matrix-multiplication-on-the-gpu.html">Stream-K: Work-centric Parallel Decomposition for Dense Matrix-Matrix Multiplication on the GPU</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/08/25/scaling-up-memory-disaggregated-applications-with-smart.html">Scaling Up Memory Disaggregated Applications with Smart</a></p>
  </li>
  <li>
    <p><a href="/papercache/mlsys/networking/2025/08/25/scale-up-ethernet-framework-scale-up-ethernet-framework-specification.html">Scale-Up Ethernet Framework Scale-Up Ethernet Framework Specification</a></p>
  </li>
</ul>

<hr />
<blockquote>
  <p><a href="/papercache/collection.html">æŸ¥çœ‹æ‰€æœ‰è®ºæ–‡â€¦</a></p>
</blockquote>

  </div>

</article>

      </div>
    </main></body>

</html>
